{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### SpeechAnalyzer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Progetto Technologies for Advanced Programming 2019/2020\n",
    "\n",
    "- Aldo Fiorito X81000447\n",
    "- Francesco Petrosino X81000533\\\n",
    "Studenti presso Università di Catania cdl Informatica"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Idea e scopo di SpeechAnalyzer\n",
    "L'idea è nata osservando una community di persone all'interno dell'applicativo VOIP per le chat vocali Discord.\\ La domanda principale posta è stata \"Chi è il più chiacchierone del gruppo?\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Bisogna fare prima una premessa ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "![](train.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Da qui SpeechAnalyzer\n",
    "\n",
    "Fornisce statistiche e metriche su numerosi flussi vocali all'interno della propria rete"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Architettura dell'applicativo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### In breve\n",
    "1. L'utente si registra all'applicativo\n",
    "2. Un file json costruito dal suo flusso vocale viene mandato a un kafka-producer, avente come topic un campo   specificato dall'user\n",
    "3. Spark , essendo anche kafka-consumer , processa ed elabora altre informazioni dal dato e costruisce un datafraframe attraverso sparksql \n",
    "4. La nuova struttura creata viene indicizzata su elasticsearch\n",
    "5. Kibana si occupa di ottenere le metriche e le statistiche dai dati indicizzati attraverso un'interfaccia user-end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Flusso operativo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "L'utente,tramite una form, viene fatto registrare all'applicativo inserendo il proprio nome,la propria compagnia( che sarà il topic kafka) e la propria lingua d'appartenenza.\\\n",
    "**Perchè la lingua?**\n",
    "Perchè l'analizzatore riesce ad elaborare qualiasi lingua ( al momento le 5 principali ).\\\n",
    "Ogni input verrà tradotto nella stessa lingua"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### PreProcessing del dato\n",
    "Un primo step di preprocessing dell'input vocale è quello di filtraggio del testo.\\\n",
    "Attraverso un file in locale di \"badwords\" verranno sostituite quelle parole considerate blasfeme o offensive\n",
    "Come secondo step il testo filtrato viene tradotto in inglese\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Kafka\n",
    "E' la prima tecnologia della pipeline che andremo ad utilizzare\n",
    "( spiegare kafka e zookeaper )\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "Il topic-kafka verrà creato da codice python:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "admin_client = KafkaAdminClient(\n",
    "                   bootstrap_servers=\"192.168.1.28:9092\", \n",
    "                   client_id='test'\n",
    "               )\n",
    "topic_list = [NewTopic(name=topicKafka, num_partitions=1, replication_factor=1)]\n",
    "admin_client.create_topics(new_topics=topic_list, validate_only=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Il file json inviato al kafka-producer avrà questa struttura :\\\\ \n",
    "\n",
    "{\"name\":\"saro\" , \"message\" : \"Microsoft has released security updates \",\"topic\" : \"Tech\",\"language\" : \"en\",\"id\":\"75df85bf\"}\n",
    "\n",
    "Dove topic si riferisce al predict ottenuto dall'algoritmo di kmeans implementato."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Modello Machine Learning e K-means"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "![](ml.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "L'immagine appena mostrata rappresenta il modello di kmeans utilizzato e salvato in locale attraverso la libreria \"pickle\".\n",
    "Per inizializzare il modello è stato dato in pasto un dataset di news ottenuto al seguente indirizzo URL\n",
    "http://mlg.ucd.ie/datasets/bbc.html.\n",
    "Le news appartengono a 5 categorie diverse: business, entertainment, politics, sport, tech.\n",
    "Questi documenti raw devono essere processati prima di essere passati all'algoritmo.\n",
    "StopWords,rimuovere le parole insignificanti\n",
    "Stemming,portare le parole alla root form\n",
    "tokenization , per"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Salvataggio e restore del modello ML\n",
    "k_model=MLAPI()\n",
    "Pkl_Filename = \"kmodel.pkl\"\n",
    "    with open(os.path.join('./python/bin/MachineL',Pkl_Filename), 'wb') as file:  \n",
    "        pickle.dump(k_model,file)\n",
    "        \n",
    "with open('./python/bin/MachineL/kmodel.pkl', 'rb') as f:\n",
    "        model = pickle.load(f)      "
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
